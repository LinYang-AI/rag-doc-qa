{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d236d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d1f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Documents\\LLM - Projects\\rag-doc-qa\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, str(Path(__file__).parent.parent))\n",
    "\n",
    "from rag_doc_qa.splitter import TextSplitter, Chunk\n",
    "from rag_doc_qa.ingest import Document\n",
    "from rag_doc_qa.config import ChunkingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1dec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ChunkingConfig(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "splitter = TextSplitter(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2c5b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.chunk_cache, splitter.config.chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47495476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rag_doc_qa.splitter:long text split into 100 chunks\n",
      "INFO:rag_doc_qa.splitter:Total chunks: 100\n",
      "INFO:rag_doc_qa.splitter:Total captured length: 27561 / 13899\n"
     ]
    }
   ],
   "source": [
    "long_content = \"\\n\".join([\"This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.\"] * 100)\n",
    "\n",
    "long_doc = Document(\n",
    "    content=long_content,\n",
    "    metadata={\"source\": \"long.txt\"},\n",
    "    doc_id=\"long_doc\",\n",
    "    source=\"long.txt\"\n",
    ")\n",
    "\n",
    "chunks = splitter.split_document(long_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea09bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '0-138'}, start_char=0, end_char=138),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '0-277'}, start_char=0, end_char=277),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '139-416'}, start_char=139, end_char=416),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '278-555'}, start_char=278, end_char=555),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '417-694'}, start_char=417, end_char=694),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '556-833'}, start_char=556, end_char=833),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '695-972'}, start_char=695, end_char=972),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '834-1111'}, start_char=834, end_char=1111),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '973-1250'}, start_char=973, end_char=1250),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1112-1389'}, start_char=1112, end_char=1389),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1251-1528'}, start_char=1251, end_char=1528),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1390-1667'}, start_char=1390, end_char=1667),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1529-1806'}, start_char=1529, end_char=1806),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1668-1945'}, start_char=1668, end_char=1945),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1807-2084'}, start_char=1807, end_char=2084),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '1946-2223'}, start_char=1946, end_char=2223),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2085-2362'}, start_char=2085, end_char=2362),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2224-2501'}, start_char=2224, end_char=2501),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2363-2640'}, start_char=2363, end_char=2640),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2502-2779'}, start_char=2502, end_char=2779),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2641-2918'}, start_char=2641, end_char=2918),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2780-3057'}, start_char=2780, end_char=3057),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '2919-3196'}, start_char=2919, end_char=3196),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3058-3335'}, start_char=3058, end_char=3335),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3197-3474'}, start_char=3197, end_char=3474),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3336-3613'}, start_char=3336, end_char=3613),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3475-3752'}, start_char=3475, end_char=3752),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3614-3891'}, start_char=3614, end_char=3891),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3753-4030'}, start_char=3753, end_char=4030),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '3892-4169'}, start_char=3892, end_char=4169),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4031-4308'}, start_char=4031, end_char=4308),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4170-4447'}, start_char=4170, end_char=4447),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4309-4586'}, start_char=4309, end_char=4586),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4448-4725'}, start_char=4448, end_char=4725),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4587-4864'}, start_char=4587, end_char=4864),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4726-5003'}, start_char=4726, end_char=5003),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '4865-5142'}, start_char=4865, end_char=5142),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5004-5281'}, start_char=5004, end_char=5281),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5143-5420'}, start_char=5143, end_char=5420),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5282-5559'}, start_char=5282, end_char=5559),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5421-5698'}, start_char=5421, end_char=5698),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5560-5837'}, start_char=5560, end_char=5837),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5699-5976'}, start_char=5699, end_char=5976),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5838-6115'}, start_char=5838, end_char=6115),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '5977-6254'}, start_char=5977, end_char=6254),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6116-6393'}, start_char=6116, end_char=6393),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6255-6532'}, start_char=6255, end_char=6532),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6394-6671'}, start_char=6394, end_char=6671),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6533-6810'}, start_char=6533, end_char=6810),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6672-6949'}, start_char=6672, end_char=6949),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6811-7088'}, start_char=6811, end_char=7088),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '6950-7227'}, start_char=6950, end_char=7227),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7089-7366'}, start_char=7089, end_char=7366),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7228-7505'}, start_char=7228, end_char=7505),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7367-7644'}, start_char=7367, end_char=7644),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7506-7783'}, start_char=7506, end_char=7783),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7645-7922'}, start_char=7645, end_char=7922),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7784-8061'}, start_char=7784, end_char=8061),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '7923-8200'}, start_char=7923, end_char=8200),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8062-8339'}, start_char=8062, end_char=8339),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8201-8478'}, start_char=8201, end_char=8478),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8340-8617'}, start_char=8340, end_char=8617),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8479-8756'}, start_char=8479, end_char=8756),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8618-8895'}, start_char=8618, end_char=8895),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8757-9034'}, start_char=8757, end_char=9034),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '8896-9173'}, start_char=8896, end_char=9173),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9035-9312'}, start_char=9035, end_char=9312),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9174-9451'}, start_char=9174, end_char=9451),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9313-9590'}, start_char=9313, end_char=9590),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9452-9729'}, start_char=9452, end_char=9729),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9591-9868'}, start_char=9591, end_char=9868),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9730-10007'}, start_char=9730, end_char=10007),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '9869-10146'}, start_char=9869, end_char=10146),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10008-10285'}, start_char=10008, end_char=10285),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10147-10424'}, start_char=10147, end_char=10424),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10286-10563'}, start_char=10286, end_char=10563),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10425-10702'}, start_char=10425, end_char=10702),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10564-10841'}, start_char=10564, end_char=10841),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10703-10980'}, start_char=10703, end_char=10980),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10842-11119'}, start_char=10842, end_char=11119),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '10981-11258'}, start_char=10981, end_char=11258),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11120-11397'}, start_char=11120, end_char=11397),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11259-11536'}, start_char=11259, end_char=11536),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11398-11675'}, start_char=11398, end_char=11675),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11537-11814'}, start_char=11537, end_char=11814),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11676-11953'}, start_char=11676, end_char=11953),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11815-12092'}, start_char=11815, end_char=12092),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '11954-12231'}, start_char=11954, end_char=12231),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12093-12370'}, start_char=12093, end_char=12370),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12232-12509'}, start_char=12232, end_char=12509),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12371-12648'}, start_char=12371, end_char=12648),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12510-12787'}, start_char=12510, end_char=12787),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12649-12926'}, start_char=12649, end_char=12926),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12788-13065'}, start_char=12788, end_char=13065),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '12927-13204'}, start_char=12927, end_char=13204),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '13066-13343'}, start_char=13066, end_char=13343),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '13205-13482'}, start_char=13205, end_char=13482),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '13344-13621'}, start_char=13344, end_char=13621),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '13483-13760'}, start_char=13483, end_char=13760),\n",
       " Chunk(text='This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality. This is a very long test sentence that contains many words and exceeds the chunk size limit to test the long text splitting functionality.', chunk_id='4b426c1c6e4d4db822980e27024330ca', doc_id='long_doc', metadata={'source': 'long.txt', 'chunk_index': 0, 'char_range': '13622-13899'}, start_char=13622, end_char=13899)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce72719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27561"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_length = sum(len(c.text) for c in chunks)\n",
    "total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73dbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert total_length >= len(long_content) * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bfd4826",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mchunk_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    assert len(chunk.text) <= splitter.config.chunk_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55516c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter.config.chunk_size * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a0592cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 (len=138\n",
      "Chunk 1 (len=277\n",
      "Chunk 2 (len=277\n",
      "Chunk 3 (len=277\n",
      "Chunk 4 (len=277\n",
      "Chunk 5 (len=277\n",
      "Chunk 6 (len=277\n",
      "Chunk 7 (len=277\n",
      "Chunk 8 (len=277\n",
      "Chunk 9 (len=277\n",
      "Chunk 10 (len=277\n",
      "Chunk 11 (len=277\n",
      "Chunk 12 (len=277\n",
      "Chunk 13 (len=277\n",
      "Chunk 14 (len=277\n",
      "Chunk 15 (len=277\n",
      "Chunk 16 (len=277\n",
      "Chunk 17 (len=277\n",
      "Chunk 18 (len=277\n",
      "Chunk 19 (len=277\n",
      "Chunk 20 (len=277\n",
      "Chunk 21 (len=277\n",
      "Chunk 22 (len=277\n",
      "Chunk 23 (len=277\n",
      "Chunk 24 (len=277\n",
      "Chunk 25 (len=277\n",
      "Chunk 26 (len=277\n",
      "Chunk 27 (len=277\n",
      "Chunk 28 (len=277\n",
      "Chunk 29 (len=277\n",
      "Chunk 30 (len=277\n",
      "Chunk 31 (len=277\n",
      "Chunk 32 (len=277\n",
      "Chunk 33 (len=277\n",
      "Chunk 34 (len=277\n",
      "Chunk 35 (len=277\n",
      "Chunk 36 (len=277\n",
      "Chunk 37 (len=277\n",
      "Chunk 38 (len=277\n",
      "Chunk 39 (len=277\n",
      "Chunk 40 (len=277\n",
      "Chunk 41 (len=277\n",
      "Chunk 42 (len=277\n",
      "Chunk 43 (len=277\n",
      "Chunk 44 (len=277\n",
      "Chunk 45 (len=277\n",
      "Chunk 46 (len=277\n",
      "Chunk 47 (len=277\n",
      "Chunk 48 (len=277\n",
      "Chunk 49 (len=277\n",
      "Chunk 50 (len=277\n",
      "Chunk 51 (len=277\n",
      "Chunk 52 (len=277\n",
      "Chunk 53 (len=277\n",
      "Chunk 54 (len=277\n",
      "Chunk 55 (len=277\n",
      "Chunk 56 (len=277\n",
      "Chunk 57 (len=277\n",
      "Chunk 58 (len=277\n",
      "Chunk 59 (len=277\n",
      "Chunk 60 (len=277\n",
      "Chunk 61 (len=277\n",
      "Chunk 62 (len=277\n",
      "Chunk 63 (len=277\n",
      "Chunk 64 (len=277\n",
      "Chunk 65 (len=277\n",
      "Chunk 66 (len=277\n",
      "Chunk 67 (len=277\n",
      "Chunk 68 (len=277\n",
      "Chunk 69 (len=277\n",
      "Chunk 70 (len=277\n",
      "Chunk 71 (len=277\n",
      "Chunk 72 (len=277\n",
      "Chunk 73 (len=277\n",
      "Chunk 74 (len=277\n",
      "Chunk 75 (len=277\n",
      "Chunk 76 (len=277\n",
      "Chunk 77 (len=277\n",
      "Chunk 78 (len=277\n",
      "Chunk 79 (len=277\n",
      "Chunk 80 (len=277\n",
      "Chunk 81 (len=277\n",
      "Chunk 82 (len=277\n",
      "Chunk 83 (len=277\n",
      "Chunk 84 (len=277\n",
      "Chunk 85 (len=277\n",
      "Chunk 86 (len=277\n",
      "Chunk 87 (len=277\n",
      "Chunk 88 (len=277\n",
      "Chunk 89 (len=277\n",
      "Chunk 90 (len=277\n",
      "Chunk 91 (len=277\n",
      "Chunk 92 (len=277\n",
      "Chunk 93 (len=277\n",
      "Chunk 94 (len=277\n",
      "Chunk 95 (len=277\n",
      "Chunk 96 (len=277\n",
      "Chunk 97 (len=277\n",
      "Chunk 98 (len=277\n",
      "Chunk 99 (len=277\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i} (len={len(chunk.text)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-doc-qa (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
